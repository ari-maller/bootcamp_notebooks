{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d698833",
   "metadata": {},
   "source": [
    "## Strings, Input and Output\n",
    "1. print/input\n",
    "2. f-strings\n",
    "3. formating strings\n",
    "4. read/write files\n",
    "5. numpy/pandas\n",
    "6. astropy read_fits\n",
    "7. hdf5\n",
    "8. Reading filenames in python\n",
    "9. Annotating plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d230ceda",
   "metadata": {},
   "source": [
    "#### 1) print/input\n",
    "The print() and input() functions allow text to be written to standard output (the screen) and taken from standard input (the keyboard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd9aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The next line will ask for input\")\n",
    "x=input(\"Input a number:\")\n",
    "print(x,\"is a string unless we convert it to \",float(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6029337",
   "metadata": {},
   "source": [
    "#### 2) f-strings \n",
    "There are a few different ways to change the ways strings behave. This different types of strings are created by putting a letter in front of the quotes mark. The most useful of these are f-strings. An f-string allows one to place variables into your string and format them. They are super convient. There are also raw-strings. In normal strings the \\ is used to denote special characters like endline (\\n) or tab (\\t) like  which make all special characters just text. They are mostly useful for passing LaTex markup to matplotlip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050334b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=3\n",
    "print(\"The value of x is \\t {10*x}\")  # \\t is tab \\n is endline\n",
    "print(f\"The value of x is \\t {10*x}\") #an f-string allows you to pass a value in {}\n",
    "print(r\"The value of x is \\t {10*x}\") #a raw-string ignores special characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0668fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(f\"The value of pi is {np.pi}\")\n",
    "print(f\"The value of pi is {np.pi:.3f}\")\n",
    "print(f\"The value of pi is {np.pi:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7622d618",
   "metadata": {},
   "source": [
    "#### 3) String Formating\n",
    "The general way to format strings in Python is to use the format method. This can insert variables like the f-string and format how they appear. The format codes are totally not obvious and you just have to look them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81e26ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi=np.pi\n",
    "G=5.67e-11\n",
    "mill = 1_000_000\n",
    "print(\"The variables {:.2e} and {:.2e} and {:8e}\".format(pi,G,mill))\n",
    "print(\"The variables {:.2f} and {:.2f} and {:10}\".format(pi,G,mill))\n",
    "print(\"The variables {:.2} and {:.2e} and {:,}\".format(pi,G,mill))\n",
    "print(\"{:10.7}  {:>10}  {:>10.2%}\".format(pi,G,0.8))     # > left justified\n",
    "print(\"{:<10.3}  {:<10}  {:>10}\".format(pi,G,mill)) # < right justified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c0531f",
   "metadata": {},
   "source": [
    "#### 4) Reading/Writing Files\n",
    "Python has functions to read and write files. You will not need to use them if you have data in some standard format like cvs, fits, pkl or hdf5. However, if you ever need to you can read and write files using the open function. This function opens an instance of a file which then has methods for reading and writing to the file. It is common to open a file in a with block so that it is automatically closed when you are done. The open function takes the filename and a letter to signify if you want to read, write or append to the file. Write will create a new file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e14fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to read a file \n",
    "v1=[]\n",
    "v2=[]\n",
    "v3=[]\n",
    "with open('hubble1929_table1.dat','r') as f:\n",
    "    for line in f:  #read one line from the file or line=f.readline()\n",
    "        if line[0]!='#': #check that it isn't a comment\n",
    "            vals=line.split()  #split the line by blank spaces\n",
    "            v1.append(int(vals[0]))\n",
    "            v2.append(float(vals[1]))\n",
    "            v3.append(int(vals[2]))\n",
    "\n",
    "print(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to write a file\n",
    "with open('tmp.dat','w') as f:\n",
    "    for i in range(len(v1)):\n",
    "        f.write(f'{v1[i]:10} {v2[i]:10.3f} {v3[i]:10} \\n')  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head tmp.dat "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b777f7",
   "metadata": {},
   "source": [
    "#### 5) numpy and pandas\n",
    "Of course column data is very common so pleny of packages have functions to read it. Numpy has np.loadtxt(), while pandas has pd.read_csv().  These functions have lots of options that make them likely to be able to read any column seperated file, as long as you choose the right ones. If you have missing values you will nee to use np.genfrontxt() instead. If your columns are fixed with pd.read_csv() won't work, you can use pd.read_fwf() or numpy.\n",
    "\n",
    "You can also write these files using np.savetxt() or df.to_csv(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=np.loadtxt('hubble1929_table1.dat', comments='#')\n",
    "print(data[:,1])\n",
    "np.savetxt('tmp.dat', data, fmt='%8d, %8.3f, %8d')\n",
    "!head -5 tmp.dat\n",
    "df=pd.read_csv('tmp.dat',  delimiter=',',  #need the commas \n",
    "                   names=['obj','dis','vel'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb11c88e",
   "metadata": {},
   "source": [
    "#### 6) astropy fits\n",
    "Astronomy uses a special file structure called a fits file to store images and tables. The astropy package provides readers and writers for this file type. There are 2 things that can make fits files complicated. First, they have a header which may contain useful information. Second, they can contain multiple images, tables or combinations of the two. As long as you have just one table or image in the file and don't need the header you can just read the file with the Table.read() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beadfc81-02b1-44d0-a19d-3048b51c5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy\n",
    "from astropy.io import fits\n",
    "\n",
    "fits_image_filename = astropy.io.fits.util.get_testdata_filepath('test0.fits')\n",
    "hdul = fits.open(fits_image_filename)\n",
    "hdul.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da283c0-5134-4e4e-85c3-2565a7286d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdul[0].header['DATE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a165db1-f25a-424c-ac51-e2cdf3cd40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hdul[1].data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0148618-f7cb-4eef-aeb5-ac78f31518da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import utils\n",
    "image_file = astropy.utils.data.get_pkg_data_filename('tutorials/FITS-images/HorseHead.fits')\n",
    "astropy.io.fits.info(image_file)\n",
    "image_data = fits.getdata(image_file, ext=0)\n",
    "\n",
    "plt.imshow(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48fa16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a file with a single table can be read using the Table class\n",
    "from astropy.table import Table\n",
    "\n",
    "tab = Table.read('edr3_nearby_brightest.fits') #tab is an astropy table\n",
    "df = tab.to_pandas() #this converts it to a pandas dataframe\n",
    "\n",
    "#in general one has to open the file and see what it there\n",
    "with aio.fits.open('edr3_nearby_brightest.fits') as hdul:\n",
    "    print(hdul.info(),'\\n')\n",
    "    print(hdul[0].header,'\\n')\n",
    "    print(f'The TTYPE1 for file 1 is {hdul[1].header[\"TTYPE1\"]} \\n')\n",
    "    data = hdul[1].data #tables can't be primary so it is the 2nd entry\n",
    "    cols = hdul[1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cols.names)\n",
    "print(data['Gmag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e84475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new hdul and saving it\n",
    "import numpy as np\n",
    "n = np.arange(100.0) #some numpy array\n",
    "hdu = aio.fits.PrimaryHDU(n) #make it a primary HDU\n",
    "hdul = aio.fits.HDUList([hdu]) #create an HDUList\n",
    "hdul.writeto('tmp.fits')  #write the first file\n",
    "\n",
    "#a astropy table can be written straight to fits format\n",
    "tab.write('tmp2.fits',format='fits') #note will give error if file exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d830c4f",
   "metadata": {},
   "source": [
    "##### 7) hdf5 files \n",
    "Another common file type is hdf5. Like fits files these are a very general way to store data and particularly good for large amounts of data.  Many numerical simulations save their outputs in hdf5 file format. Packages for analyzing simulations will read these files, like yt or pynbody. But if you need to read the file directly you can use h5py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc71a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File('fof_subhalo_tab_015.hdf5', 'r')\n",
    "print(list(f.keys())) #Groups in the file\n",
    "print(f['Group'].keys()) \n",
    "ds = f['Group/Group_M_Crit200'] #this is an actual dataset\n",
    "print(ds.shape,ds.dtype,ds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe5791",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ds)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Group $M_{Crit200}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8dc32",
   "metadata": {},
   "source": [
    "#### 8) Getting filenames in python\n",
    "Python offers a number of ways to navigate your file system. The easiest is the os package which gives you functions that are very similar to what you can do on the command line. In order to use wildcards use the glob package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0abb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/ari/Documents/python/bootcamp_notebooks')\n",
    "print(f'current directory is {os.getcwd()} \\n')\n",
    "os.chdir('../')\n",
    "print(f'now in {os.getcwd()} directory\\n')\n",
    "os.chdir('bootcamp_notebooks')\n",
    "print(os.listdir('/'),'\\n')\n",
    "files = os.listdir() #if listing not the current directory will have to add path \n",
    "print(files[20])\n",
    "size = os.path.getsize(files[20])\n",
    "print(f'the size of this file is {size} bytes \\n')\n",
    "os.path.isfile('2d_plotting_examples.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f003a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "\n",
    "print(glob.glob('*.dat'))\n",
    "print(glob.glob('Numpy*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6658641c",
   "metadata": {},
   "source": [
    "#### 9) Annotating plots\n",
    "Finally we may want to put strings on our plots. Besides using the label and title methods we can text and annotate to and text anywhere on a matplotlib plot.  We can also use LaTex markup to get greek letters and math symbols. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e8609",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ds)\n",
    "plt.title(r'Cool mathy $\\Phi(m) = \\alpha m^{\\beta}$ title') #raw-string\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Group $M_{Crit200}$')\n",
    "plt.text(5,100,'mass function')\n",
    "plt.text(6,20,'goes down',rotation=-45,color='brown')\n",
    "plt.annotate('few high \\n mass object',(20,10),ha='center')\n",
    "plt.annotate('just one',(25,1.5),xytext=(15,3),\n",
    "             arrowprops=dict(facecolor='blue', shrink=0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de307e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
